{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca321b2-449f-4b30-a7ca-a16dd5881ebf",
   "metadata": {},
   "source": [
    "## **English → Tamil Translation using Seq2Seq (LSTM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca648396-3e11-4e61-b5b5-02952d02aba4",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "32964804-c221-43e7-885e-e4f934154b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a469d-0f28-4480-991e-bc24a7a698b2",
   "metadata": {},
   "source": [
    "### **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "55a320b4-6b8d-4d28-97f8-f1a3a6926405",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"engtamilTrain.csv\")\n",
    "train = train.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "english_sentences = train[\"en\"].astype(str).head(2000)\n",
    "tamil_sentences   = train[\"ta\"].astype(str).head(2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "22dc1f8d-1d0c-4286-b373-ab4192d415fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995           Sreya is paired with Rajini in 'Sivaji'.\\n\n",
       "1996    It has opposed every form of Sinhalese chauvin...\n",
       "1997    Yet his meat in his bowels is turned, it is th...\n",
       "1998    Eight of the 26 are currently employed on full...\n",
       "1999    And changed his prison garments: and he did ea...\n",
       "Name: en, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fe6f8413-15ae-4095-85a3-cd719e2b3104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995     'சிவாஜி'யில் ரஜினி ஜோடியாக ஷ்ரேயா நடிக்கிறார்.\\n\n",
       "1996    தமிழீழ விடுதலைப் புலிகளின் வங்குரோத்தானதும் ப...\n",
       "1997    அவன் போஜனம் அவன் குடல்களில் மாறி, அவனுக்குள் வ...\n",
       "1998    இந்த 26 பேரில் 8 பேர் முழுச் சம்பளத்தில் மீளச்...\n",
       "1999    அவனுடைய சிறைச்சாலை வஸ்திரங்களை மாற்றினான்; அவன...\n",
       "Name: ta, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tamil_sentences.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed9aeb-9e4c-4264-afd2-bad367c2b8dc",
   "metadata": {},
   "source": [
    "### **Add SOS> and <EOS (ONLY to Tamil)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d2d1ef7d-fc6a-4644-b6ba-c17b6b8b1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sos_eos(sentences):\n",
    "    return [\"<SOS> \" + s + \" <EOS>\" for s in sentences]\n",
    "\n",
    "tamil_sentences = add_sos_eos(tamil_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae0397-7cf9-48e7-a9ee-8df0d3c2c46e",
   "metadata": {},
   "source": [
    "### **Tokenization (Words → Numbers)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7a270e17-0aae-4281-848d-7ed11eb29fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tokenizer = Tokenizer(filters=\"\")\n",
    "tamil_tokenizer   = Tokenizer(filters=\"\")\n",
    "\n",
    "english_tokenizer.fit_on_texts(english_sentences) #eg-[1,2,3,4,5]\n",
    "tamil_tokenizer.fit_on_texts(tamil_sentences)\n",
    "\n",
    "english_sequences = english_tokenizer.texts_to_sequences(english_sentences)\n",
    "tamil_sequences   = tamil_tokenizer.texts_to_sequences(tamil_sentences)#eg-[2,3,4,2]\n",
    "\n",
    "english_vocab_size = len(english_tokenizer.word_index) + 1\n",
    "tamil_vocab_size   = len(tamil_tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ef51fdec-e85d-4fb5-996a-8edfee8dbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11162\n",
      "17357\n"
     ]
    }
   ],
   "source": [
    "print(english_vocab_size)\n",
    "print(tamil_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5717e6-8aca-4733-a08c-fb4952eac6ff",
   "metadata": {},
   "source": [
    "### **Padding (Fix Sequence Length)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "759c910f-bbd4-4dee-9f8c-d71aaac431be",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_len  = 20\n",
    "max_output_len = 20\n",
    "\n",
    "encoder_input_sequences = pad_sequences(\n",
    "    english_sequences,\n",
    "    maxlen=max_input_len,\n",
    "    padding=\"post\"\n",
    ")\n",
    "\n",
    "decoder_full_sequences = pad_sequences(\n",
    "    tamil_sequences,\n",
    "    maxlen=max_output_len,\n",
    "    padding=\"post\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e715dd-5fc8-4468-81cc-06b58de90b04",
   "metadata": {},
   "source": [
    "### **Teacher Forcing (Decoder Input & Target)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3fa8bc6a-368c-430a-9fb6-8b09d921466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_sequences  = decoder_full_sequences[:, :-1]\n",
    "decoder_target_sequences = decoder_full_sequences[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2b07fc74-b0fb-44d6-b91c-a4fa66b6d2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3588,    63,  3589, ...,     0,     0,     0],\n",
       "       [ 3595,    54,   679, ...,     2,     0,     0],\n",
       "       [ 3604,  3605,   875, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [   20, 17338,    20, ...,     0,     0,     0],\n",
       "       [    6, 17344,   497, ...,     0,     0,     0],\n",
       "       [  171, 17350, 17351, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d396785-4cc7-490f-82b1-27e7a27ba0c9",
   "metadata": {},
   "source": [
    "### **Load Word2Vec Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0d9f46e4-a145-4d8f-a215-3a1f824a471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already created engmodel and tammodel on wordembedding practice notebook and saved\n",
    "# Import ting from there\n",
    "eng_model = Word2Vec.load(\"engmodel.bin\")\n",
    "tam_model = Word2Vec.load(\"tammodel.bin\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb504de4-3cbf-4b0a-9582-d935e7ae5b8c",
   "metadata": {},
   "source": [
    "### **Create Embedding Matrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d1f1b053-1942-424b-ae70-70d777b1ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(w2v_model, tokenizer, vocab_size):\n",
    "    embedding_dim = w2v_model.vector_size\n",
    "    matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        if word in w2v_model.wv:\n",
    "            matrix[idx] = w2v_model.wv[word]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "eng_embedding_matrix = create_embedding_matrix(\n",
    "    eng_model, english_tokenizer, english_vocab_size\n",
    ")\n",
    "\n",
    "tam_embedding_matrix = create_embedding_matrix(\n",
    "    tam_model, tamil_tokenizer, tamil_vocab_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6dc86c8c-2f6e-4dee-a375-54d42f8746f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11162, 100)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8ee89b39-2c6b-4a1c-88e1-7d31e4af77cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17357, 100)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tam_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec30c4-24dc-4090-9d57-ba570d58db86",
   "metadata": {},
   "source": [
    "def create_seq2seq_model(input_vocab_size, output_vocab_size, input_seq_length, output_seq_length, hidden_units, eng_embedding_matrix, tam_embedding_matrix):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(input_seq_length,))\n",
    "    encoder_embedding = Embedding(input_vocab_size, hidden_units, weights=[eng_embedding_matrix], trainable=False)(encoder_inputs)\n",
    "    encoder_lstm, encoder_state_h, encoder_state_c = LSTM(hidden_units, return_state=True)(encoder_embedding)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(output_seq_length,))\n",
    "    decoder_embedding = Embedding(output_vocab_size, hidden_units, weights=[tam_embedding_matrix], trainable=False)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[encoder_state_h, encoder_state_c])\n",
    "    decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54eb12-8043-4650-a024-1b960f0ec703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f245ccc4-d87e-4b94-894a-3e57ae0b246c",
   "metadata": {},
   "source": [
    "### **Build Seq2Seq Model (Encoder–Decoder)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fcb9b4-2035-4f87-8ec9-80d21f723faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bb106f04-190a-4e80-9115-3a6cbcda6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_len,))\n",
    "encoder_embed = Embedding(\n",
    "    english_vocab_size,\n",
    "    latent_dim,\n",
    "    weights=[eng_embedding_matrix],\n",
    "    trainable=False\n",
    ")(encoder_inputs)\n",
    "\n",
    "encoder_outputs, state_h, state_c = LSTM(\n",
    "    latent_dim, return_state=True\n",
    ")(encoder_embed)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_len - 1,))\n",
    "decoder_embed = Embedding(\n",
    "    tamil_vocab_size,\n",
    "    latent_dim,\n",
    "    weights=[tam_embedding_matrix],\n",
    "    trainable=False\n",
    ")(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(\n",
    "    latent_dim,\n",
    "    return_sequences=True,\n",
    "    return_state=True\n",
    ")\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "    decoder_embed,\n",
    "    initial_state=[state_h, state_c]\n",
    ")\n",
    "\n",
    "decoder_dense = Dense(tamil_vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Training Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7796387-87ea-4c03-a427-cb8d6ed44751",
   "metadata": {},
   "source": [
    "### **Compile & Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8b291298-1a20-4d7a-b4db-1671298347f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,116,200</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,700</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)]        │                 │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17357</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,753,057</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │       \u001b[38;5;34m1,116,200\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │       \u001b[38;5;34m1,735,700\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m80,400\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│                               │ \u001b[38;5;34m100\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,  │          \u001b[38;5;34m80,400\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │ \u001b[38;5;34m100\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)]        │                 │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m17357\u001b[0m)         │       \u001b[38;5;34m1,753,057\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,765,757</span> (18.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,765,757\u001b[0m (18.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,913,857</span> (7.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,913,857\u001b[0m (7.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,851,900</span> (10.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,851,900\u001b[0m (10.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 252ms/step - accuracy: 0.2332 - loss: 9.3689 - val_accuracy: 0.2612 - val_loss: 7.6371\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - accuracy: 0.2423 - loss: 7.0159 - val_accuracy: 0.2612 - val_loss: 7.4407\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 256ms/step - accuracy: 0.2450 - loss: 6.7370 - val_accuracy: 0.2612 - val_loss: 7.5711\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 237ms/step - accuracy: 0.2494 - loss: 6.6375 - val_accuracy: 0.2646 - val_loss: 7.6433\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - accuracy: 0.2440 - loss: 6.6407 - val_accuracy: 0.2634 - val_loss: 7.7364\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 230ms/step - accuracy: 0.2519 - loss: 6.5405 - val_accuracy: 0.2642 - val_loss: 7.7825\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - accuracy: 0.2438 - loss: 6.5448 - val_accuracy: 0.2653 - val_loss: 7.8198\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 271ms/step - accuracy: 0.2516 - loss: 6.4355 - val_accuracy: 0.2634 - val_loss: 7.8425\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 254ms/step - accuracy: 0.2429 - loss: 6.4861 - val_accuracy: 0.2643 - val_loss: 7.8803\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 250ms/step - accuracy: 0.2541 - loss: 6.3506 - val_accuracy: 0.2661 - val_loss: 7.9307\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 262ms/step - accuracy: 0.2498 - loss: 6.3328 - val_accuracy: 0.2664 - val_loss: 7.9446\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 0.2508 - loss: 6.2810 - val_accuracy: 0.2664 - val_loss: 8.0061\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step - accuracy: 0.2615 - loss: 6.1556 - val_accuracy: 0.2674 - val_loss: 8.0395\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - accuracy: 0.2450 - loss: 6.2516 - val_accuracy: 0.2663 - val_loss: 8.0601\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - accuracy: 0.2545 - loss: 6.1264 - val_accuracy: 0.2668 - val_loss: 8.1196\n",
      "Epoch 16/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - accuracy: 0.2544 - loss: 6.0856 - val_accuracy: 0.2659 - val_loss: 8.1279\n",
      "Epoch 17/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step - accuracy: 0.2442 - loss: 6.1144 - val_accuracy: 0.2672 - val_loss: 8.1586\n",
      "Epoch 18/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - accuracy: 0.2567 - loss: 5.9820 - val_accuracy: 0.2664 - val_loss: 8.2234\n",
      "Epoch 19/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - accuracy: 0.2552 - loss: 5.9355 - val_accuracy: 0.2680 - val_loss: 8.2612\n",
      "Epoch 20/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - accuracy: 0.2502 - loss: 5.9331 - val_accuracy: 0.2667 - val_loss: 8.3034\n",
      "Epoch 21/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 250ms/step - accuracy: 0.2491 - loss: 5.8930 - val_accuracy: 0.2659 - val_loss: 8.3091\n",
      "Epoch 22/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - accuracy: 0.2620 - loss: 5.7515 - val_accuracy: 0.2668 - val_loss: 8.3551\n",
      "Epoch 23/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - accuracy: 0.2567 - loss: 5.7424 - val_accuracy: 0.2674 - val_loss: 8.3885\n",
      "Epoch 24/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - accuracy: 0.2561 - loss: 5.7328 - val_accuracy: 0.2686 - val_loss: 8.4635\n",
      "Epoch 25/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step - accuracy: 0.2576 - loss: 5.6709 - val_accuracy: 0.2682 - val_loss: 8.4833\n",
      "Epoch 26/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step - accuracy: 0.2668 - loss: 5.5515 - val_accuracy: 0.2674 - val_loss: 8.5138\n",
      "Epoch 27/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - accuracy: 0.2458 - loss: 5.6645 - val_accuracy: 0.2678 - val_loss: 8.5704\n",
      "Epoch 28/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 0.2630 - loss: 5.5221 - val_accuracy: 0.2680 - val_loss: 8.5777\n",
      "Epoch 29/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 237ms/step - accuracy: 0.2477 - loss: 5.6025 - val_accuracy: 0.2687 - val_loss: 8.6246\n",
      "Epoch 30/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - accuracy: 0.2571 - loss: 5.4865 - val_accuracy: 0.2692 - val_loss: 8.6469\n",
      "Epoch 31/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - accuracy: 0.2556 - loss: 5.4693 - val_accuracy: 0.2696 - val_loss: 8.6897\n",
      "Epoch 32/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - accuracy: 0.2591 - loss: 5.4157 - val_accuracy: 0.2689 - val_loss: 8.6898\n",
      "Epoch 33/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 270ms/step - accuracy: 0.2668 - loss: 5.3087 - val_accuracy: 0.2696 - val_loss: 8.7269\n",
      "Epoch 34/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 287ms/step - accuracy: 0.2610 - loss: 5.3264 - val_accuracy: 0.2676 - val_loss: 8.7389\n",
      "Epoch 35/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 260ms/step - accuracy: 0.2512 - loss: 5.3868 - val_accuracy: 0.2679 - val_loss: 8.7683\n",
      "Epoch 36/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - accuracy: 0.2523 - loss: 5.3200 - val_accuracy: 0.2674 - val_loss: 8.8057\n",
      "Epoch 37/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - accuracy: 0.2623 - loss: 5.2200 - val_accuracy: 0.2674 - val_loss: 8.8398\n",
      "Epoch 38/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - accuracy: 0.2700 - loss: 5.1494 - val_accuracy: 0.2678 - val_loss: 8.8759\n",
      "Epoch 39/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 0.2620 - loss: 5.1755 - val_accuracy: 0.2684 - val_loss: 8.9033\n",
      "Epoch 40/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - accuracy: 0.2717 - loss: 5.0414 - val_accuracy: 0.2670 - val_loss: 8.9219\n",
      "Epoch 41/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - accuracy: 0.2524 - loss: 5.1790 - val_accuracy: 0.2679 - val_loss: 8.9483\n",
      "Epoch 42/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - accuracy: 0.2574 - loss: 5.0978 - val_accuracy: 0.2689 - val_loss: 9.0018\n",
      "Epoch 43/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - accuracy: 0.2480 - loss: 5.1421 - val_accuracy: 0.2699 - val_loss: 9.0180\n",
      "Epoch 44/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - accuracy: 0.2559 - loss: 5.0534 - val_accuracy: 0.2687 - val_loss: 9.0363\n",
      "Epoch 45/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - accuracy: 0.2567 - loss: 5.0106 - val_accuracy: 0.2682 - val_loss: 9.0476\n",
      "Epoch 46/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 243ms/step - accuracy: 0.2570 - loss: 4.9629 - val_accuracy: 0.2693 - val_loss: 9.0857\n",
      "Epoch 47/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 239ms/step - accuracy: 0.2595 - loss: 4.9489 - val_accuracy: 0.2683 - val_loss: 9.0760\n",
      "Epoch 48/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 236ms/step - accuracy: 0.2633 - loss: 4.8897 - val_accuracy: 0.2689 - val_loss: 9.1146\n",
      "Epoch 49/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 236ms/step - accuracy: 0.2683 - loss: 4.8130 - val_accuracy: 0.2686 - val_loss: 9.1400\n",
      "Epoch 50/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - accuracy: 0.2647 - loss: 4.8170 - val_accuracy: 0.2693 - val_loss: 9.1821\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_target_sequences,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acda9c8b-b279-426e-b18d-eaf748adb75d",
   "metadata": {},
   "source": [
    "### **Inference Models (REAL TRANSLATION)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c3644ffd-28ea-4312-a8e0-d69b56c50397",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(\n",
    "    encoder_inputs,\n",
    "    [state_h, state_c]\n",
    ")\n",
    "# Decoder Inference model\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_embed,\n",
    "    initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs, state_h_dec, state_c_dec]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd164ca-ec6a-4291-8eb1-d53dc224f1dd",
   "metadata": {},
   "source": [
    "### **Translation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a95197ff-237e-4df2-8dc5-a28d69c7b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence):\n",
    "    seq = english_tokenizer.texts_to_sequences([sentence])\n",
    "    seq = pad_sequences(seq, maxlen=max_input_len, padding=\"post\")\n",
    "\n",
    "    state_h, state_c = encoder_model.predict(seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tamil_tokenizer.word_index['<sos>']\n",
    "\n",
    "    decoded_sentence = []\n",
    "\n",
    "    for _ in range(max_output_len):\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq, state_h, state_c]\n",
    "        )\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tamil_tokenizer.index_word.get(sampled_token_index)\n",
    "\n",
    "        if sampled_word == '<EOS>' or sampled_word is None:\n",
    "            break\n",
    "\n",
    "        decoded_sentence.append(sampled_word)\n",
    "\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        state_h, state_c = h, c\n",
    "\n",
    "    return \" \".join(decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4249d19e-82eb-493c-9eff-bc6b5bb86349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '<eos>',\n",
       " 'மற்றும்',\n",
       " 'ஒரு',\n",
       " 'என்று',\n",
       " 'இந்த',\n",
       " 'அவர்',\n",
       " 'அமெரிக்க',\n",
       " 'அரசியல்',\n",
       " 'என்ற',\n",
       " 'அவர்கள்',\n",
       " 'நான்',\n",
       " 'இருந்து',\n",
       " 'என',\n",
       " 'அது',\n",
       " 'உள்ள',\n",
       " 'அந்த',\n",
       " 'இது',\n",
       " 'தனது',\n",
       " 'அவன்']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tamil_tokenizer.word_index.keys())[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7f9028cb-1366-4b45-8d36-153b28eb012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "அன்பின் <eos> <eos>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(translate_sentence(\"i love english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d2735d-8360-42c0-8c42-74339c590835",
   "metadata": {},
   "source": [
    "“Basic Seq2Seq without attention compresses the entire input into a single context vector, causing information loss. As a result, the decoder often predicts <EOS> early. **This is a known limitation, and attention mechanisms were introduced to solve this.”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ddb983-f511-4fe0-b027-ad2a1fdd288a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b38e53-c231-4ec9-b644-8b8f8586807c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba72cad-83e6-47aa-87c9-4cdff28dd142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3cb94-a8f7-4f69-92eb-9a92d95d6154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d7f5b-5323-438d-8e15-8f258b2449c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9e42f-df48-49e9-b8ba-e91ce26b7244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006b900-3ed9-4587-aedf-72f8161c140a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a40d0d-5313-4463-850c-5410f171ba17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24571b52-d74e-4c45-9dc0-5b27035767b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b28f6-16c2-411b-807d-d589ceb68cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64fc43-e76e-4868-97be-33002ad2d508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a181f-b5c7-4d95-8c6c-149d702d9700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565517b-e14d-49b8-b1f3-77eda3005b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b430a6-83fd-4d8e-9b69-9afd06a2e243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da86bb5-c69c-49e6-82fe-b22f089d0b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcada19-80c2-48fa-b6ff-48b3b856f194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd1761-1c4c-4bee-8798-c36aa581a0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c98ce8-514d-4f57-abb7-a34f4d6cc038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba79591-ed13-4c67-a886-257579093a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5a09f-5685-438d-85d3-bc731c00ce70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a9853-718f-4c80-8a32-479425c86531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815aac10-7a84-4dc0-b32d-932645e83a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d8ad9-cd21-42b6-a28b-b3c8d5174433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef581477-2fcc-4263-9bf0-13c0f1f92cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a709a1-fdb9-42a3-a811-fb6640a50bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02670052-e2ce-4a64-8361-1f7aa8425f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32b82b-bc44-4c23-936c-f8638af52b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb139765-8211-45ea-abad-d2253873bbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb83deb-48ac-4d21-b431-4f59dafd5d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
